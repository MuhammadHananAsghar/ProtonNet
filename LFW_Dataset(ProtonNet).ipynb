{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LFW Dataset(ProtonNet).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2TKVZOLBX7B",
        "outputId": "66281ab5-af42-4234-b256-95f156eecc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ProtonNet'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/33)\u001b[K\rremote: Counting objects:   6% (2/33)\u001b[K\rremote: Counting objects:   9% (3/33)\u001b[K\rremote: Counting objects:  12% (4/33)\u001b[K\rremote: Counting objects:  15% (5/33)\u001b[K\rremote: Counting objects:  18% (6/33)\u001b[K\rremote: Counting objects:  21% (7/33)\u001b[K\rremote: Counting objects:  24% (8/33)\u001b[K\rremote: Counting objects:  27% (9/33)\u001b[K\rremote: Counting objects:  30% (10/33)\u001b[K\rremote: Counting objects:  33% (11/33)\u001b[K\rremote: Counting objects:  36% (12/33)\u001b[K\rremote: Counting objects:  39% (13/33)\u001b[K\rremote: Counting objects:  42% (14/33)\u001b[K\rremote: Counting objects:  45% (15/33)\u001b[K\rremote: Counting objects:  48% (16/33)\u001b[K\rremote: Counting objects:  51% (17/33)\u001b[K\rremote: Counting objects:  54% (18/33)\u001b[K\rremote: Counting objects:  57% (19/33)\u001b[K\rremote: Counting objects:  60% (20/33)\u001b[K\rremote: Counting objects:  63% (21/33)\u001b[K\rremote: Counting objects:  66% (22/33)\u001b[K\rremote: Counting objects:  69% (23/33)\u001b[K\rremote: Counting objects:  72% (24/33)\u001b[K\rremote: Counting objects:  75% (25/33)\u001b[K\rremote: Counting objects:  78% (26/33)\u001b[K\rremote: Counting objects:  81% (27/33)\u001b[K\rremote: Counting objects:  84% (28/33)\u001b[K\rremote: Counting objects:  87% (29/33)\u001b[K\rremote: Counting objects:  90% (30/33)\u001b[K\rremote: Counting objects:  93% (31/33)\u001b[K\rremote: Counting objects:  96% (32/33)\u001b[K\rremote: Counting objects: 100% (33/33)\u001b[K\rremote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/30)\u001b[K\rremote: Compressing objects:   6% (2/30)\u001b[K\rremote: Compressing objects:  10% (3/30)\u001b[K\rremote: Compressing objects:  13% (4/30)\u001b[K\rremote: Compressing objects:  16% (5/30)\u001b[K\rremote: Compressing objects:  20% (6/30)\u001b[K\rremote: Compressing objects:  23% (7/30)\u001b[K\rremote: Compressing objects:  26% (8/30)\u001b[K\rremote: Compressing objects:  30% (9/30)\u001b[K\rremote: Compressing objects:  33% (10/30)\u001b[K\rremote: Compressing objects:  36% (11/30)\u001b[K\rremote: Compressing objects:  40% (12/30)\u001b[K\rremote: Compressing objects:  43% (13/30)\u001b[K\rremote: Compressing objects:  46% (14/30)\u001b[K\rremote: Compressing objects:  50% (15/30)\u001b[K\rremote: Compressing objects:  53% (16/30)\u001b[K\rremote: Compressing objects:  56% (17/30)\u001b[K\rremote: Compressing objects:  60% (18/30)\u001b[K\rremote: Compressing objects:  63% (19/30)\u001b[K\rremote: Compressing objects:  66% (20/30)\u001b[K\rremote: Compressing objects:  70% (21/30)\u001b[K\rremote: Compressing objects:  73% (22/30)\u001b[K\rremote: Compressing objects:  76% (23/30)\u001b[K\rremote: Compressing objects:  80% (24/30)\u001b[K\rremote: Compressing objects:  83% (25/30)\u001b[K\rremote: Compressing objects:  86% (26/30)\u001b[K\rremote: Compressing objects:  90% (27/30)\u001b[K\rremote: Compressing objects:  93% (28/30)\u001b[K\rremote: Compressing objects:  96% (29/30)\u001b[K\rremote: Compressing objects: 100% (30/30)\u001b[K\rremote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 33 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:   3% (1/33)   \rUnpacking objects:   6% (2/33)   \rUnpacking objects:   9% (3/33)   \rUnpacking objects:  12% (4/33)   \rUnpacking objects:  15% (5/33)   \rUnpacking objects:  18% (6/33)   \rUnpacking objects:  21% (7/33)   \rUnpacking objects:  24% (8/33)   \rUnpacking objects:  27% (9/33)   \rUnpacking objects:  30% (10/33)   \rUnpacking objects:  33% (11/33)   \rUnpacking objects:  36% (12/33)   \rUnpacking objects:  39% (13/33)   \rUnpacking objects:  42% (14/33)   \rUnpacking objects:  45% (15/33)   \rUnpacking objects:  48% (16/33)   \rUnpacking objects:  51% (17/33)   \rUnpacking objects:  54% (18/33)   \rUnpacking objects:  57% (19/33)   \rUnpacking objects:  60% (20/33)   \rUnpacking objects:  63% (21/33)   \rUnpacking objects:  66% (22/33)   \rUnpacking objects:  69% (23/33)   \rUnpacking objects:  72% (24/33)   \rUnpacking objects:  75% (25/33)   \rUnpacking objects:  78% (26/33)   \rUnpacking objects:  81% (27/33)   \rUnpacking objects:  84% (28/33)   \rUnpacking objects:  87% (29/33)   \rUnpacking objects:  90% (30/33)   \rUnpacking objects:  93% (31/33)   \rUnpacking objects:  96% (32/33)   \rUnpacking objects: 100% (33/33)   \rUnpacking objects: 100% (33/33), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MuhammadHananAsghar/ProtonNet.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0FkQ2qHjB1O1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d stoicstatic/face-recognition-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l86jaxiXB4Kv",
        "outputId": "b4f55f66-4afe-401e-9b0c-cb2b11fea8dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading face-recognition-dataset.zip to /content\n",
            " 97% 176M/181M [00:01<00:00, 171MB/s]\n",
            "100% 181M/181M [00:01<00:00, 153MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip *.zip && rm -rf *.zip"
      ],
      "metadata": {
        "id": "2ZA_xiJPB_0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/ProtonNet"
      ],
      "metadata": {
        "id": "zBKspJy3IwCR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "metadata": {
        "id": "_UJw3B5dC1uB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "YagzNUXJDHlR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '1BC33NqYdJ39QKXiD5osHKY-0a37miWEx' # URL id. \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('weights.zip')"
      ],
      "metadata": {
        "id": "UfIdKPNcDhaE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn1zqR2eDuZz",
        "outputId": "1d386fab-92a8-4d09-b353-de8e90bc4213"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adc.json      lfw-funneled.tgz\t pairs.txt  sample_data\n",
            "kaggle.json   pairsDevTest.txt\t protonnet  weights.zip\n",
            "lfw_funneled  pairsDevTrain.txt  ProtonNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip weights.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rw63rh9DwyT",
        "outputId": "db5a1e36-863b-4cff-831d-f564aeeb5063"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  weights.zip\n",
            "   creating: ProtonNet/assets/\n",
            "   creating: ProtonNet/variables/\n",
            "  inflating: ProtonNet/variables/variables.index  \n",
            "  inflating: ProtonNet/variables/variables.data-00000-of-00001  \n",
            "  inflating: ProtonNet/saved_model.pb  \n",
            "  inflating: ProtonNet/keras_metadata.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf *.zip\n",
        "!rm -rf *.txt\n",
        "!rm -rf *.json\n",
        "!rm -rf *.tgz"
      ],
      "metadata": {
        "id": "byycJxTWDzRT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd protonnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UBb9FhfJr4i",
        "outputId": "046e8bf7-3dc0-4228-c5c4-b158ec33271d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/protonnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SxgOdwYKgW8",
        "outputId": "36d21b51-dcd4-4268-98d3-ba8a20b85c87"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r protonnet.zip protonnet"
      ],
      "metadata": {
        "id": "80_yDHN_KZM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0qsoNk3D2MD",
        "outputId": "d91ab7b4-26db-4d2b-ca8d-2307cfb53b16"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t*---------------------------------------*\n",
            "\tAuthor: Muhammad Hanan Asghar\n",
            "\tModel: ProtonNet\n",
            "\tType: Recognition Tasks\n",
            "\tDate: 12-03-2022\n",
            "\tLanguage: Python\n",
            "\tTensorflow Version: 2.8.0\n",
            "\tBatch Size: 64\n",
            "\tImage Size: (128, 128, 3)\n",
            "\tEmbedding Size: 256\n",
            "  Disclaimer: I have tested if you got any error to datagenerator then make sure that you have minimum to two images per directory.\n",
            "  Otherwise it will give error.\n",
            "\t*---------------------------------------*\n",
            "\t\n",
            "2022-03-13 21:25:48.450863: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Weights Loaded.\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.2120\n",
            "Epoch 1: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 199s 966ms/step - loss: 0.2120\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1142\n",
            "Epoch 2: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 196s 982ms/step - loss: 0.1142\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0852\n",
            "Epoch 3: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 193s 964ms/step - loss: 0.0852\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0680\n",
            "Epoch 4: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 194s 971ms/step - loss: 0.0680\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0616\n",
            "Epoch 5: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 192s 963ms/step - loss: 0.0616\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0540\n",
            "Epoch 6: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 188s 940ms/step - loss: 0.0540\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0480\n",
            "Epoch 7: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 190s 950ms/step - loss: 0.0480\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0443\n",
            "Epoch 8: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 188s 942ms/step - loss: 0.0443\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0401\n",
            "Epoch 9: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 189s 948ms/step - loss: 0.0401\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0376\n",
            "Epoch 10: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 190s 949ms/step - loss: 0.0376\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0362\n",
            "Epoch 11: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 190s 953ms/step - loss: 0.0362\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0403\n",
            "Epoch 12: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 190s 951ms/step - loss: 0.0403\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 13: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 190s 949ms/step - loss: 0.0312\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0290\n",
            "Epoch 14: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 190s 951ms/step - loss: 0.0290\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0288\n",
            "Epoch 15: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 187s 938ms/step - loss: 0.0288\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0270\n",
            "Epoch 16: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 191s 955ms/step - loss: 0.0270\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0258\n",
            "Epoch 17: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 191s 958ms/step - loss: 0.0258\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 18: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 188s 940ms/step - loss: 0.0310\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0241\n",
            "Epoch 19: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 188s 942ms/step - loss: 0.0241\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0258\n",
            "Epoch 20: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 188s 942ms/step - loss: 0.0258\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0214\n",
            "Epoch 21: saving model to /content/protonnet/weights/weights.h5\n",
            "200/200 [==============================] - 190s 953ms/step - loss: 0.0214\n",
            "Epoch 22/100\n",
            " 25/200 [==>...........................] - ETA: 2:45 - loss: 0.0173Traceback (most recent call last):\n",
            "  File \"train.py\", line 46, in <module>\n",
            "    callbacks = callbacks\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1389, in fit\n",
            "    callbacks.on_train_batch_end(end_step, logs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 438, in on_train_batch_end\n",
            "    self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 297, in _call_batch_hook\n",
            "    self._call_batch_end_hook(mode, batch, logs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 318, in _call_batch_end_hook\n",
            "    self._call_batch_hook_helper(hook_name, batch, logs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 356, in _call_batch_hook_helper\n",
            "    hook(batch, logs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 1034, in on_train_batch_end\n",
            "    self._batch_update_progbar(batch, logs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 1106, in _batch_update_progbar\n",
            "    logs = tf_utils.sync_to_numpy_or_python_type(logs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\", line 563, in sync_to_numpy_or_python_type\n",
            "    return tf.nest.map_structure(_to_single_numpy_or_python_type, tensors)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 914, in map_structure\n",
            "    structure[0], [func(*x) for x in entries],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 914, in <listcomp>\n",
            "    structure[0], [func(*x) for x in entries],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\", line 557, in _to_single_numpy_or_python_type\n",
            "    t = t.numpy()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1223, in numpy\n",
            "    maybe_arr = self._numpy()  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1189, in _numpy\n",
            "    return self._numpy_internal()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RTJ_WY3YLDgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}